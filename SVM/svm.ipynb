{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Rf2BXTYg2u",
        "colab_type": "text"
      },
      "source": [
        "#Introduction to SVM for Beginners\n",
        "- This notebook will introduce you on how you can implement support vector machines.\n",
        "- The different kernel types.\n",
        "- Hyperparameters to tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06bf8fPfY3js",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH7Xd8M79WvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XspLGRtsY7z3",
        "colab_type": "text"
      },
      "source": [
        "###Read the data\n",
        "- Get the data. The data used for this tutorial can be downloaded from https://www.kaggle.com/c/intercampusai2019.\n",
        "- Seperate the class label from the original data.\n",
        "- Scale the training data and split into train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1dJ4wLsBD53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the data\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# select only numeric datatypes\n",
        "data = data.select_dtypes(['float64', 'int64'])\n",
        "\n",
        "# seperate the class and train data\n",
        "class_label = data['Promoted_or_Not']\n",
        "train_data = data.drop(data[['Promoted_or_Not']], axis=1)\n",
        "\n",
        "X = StandardScaler().fit_transform(train_data)\n",
        "\n",
        "#split the training data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, class_label, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXTgWXoraH7y",
        "colab_type": "text"
      },
      "source": [
        "### Linear SVM\n",
        "- The first model we will build is the linear svm model. This model is used if you have a linear dataset and the model can correctly identify the hyperplanes on the hypersurface.\n",
        "\n",
        "- The model is built by assigning the *linear* value to the kernel parameter as seen in the code block below.\n",
        "\n",
        "- Fit the model and predict on both train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dve4x2DdDHDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model\n",
        "linear_svm = svm.SVC(kernel='linear')\n",
        "\n",
        "# fit the model on the training data\n",
        "linear_svm.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on train data\n",
        "train_pred = linear_svm.predict(X_train)\n",
        "\n",
        "# make prediction on test data\n",
        "test_pred = linear_svm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXLyw8REat24",
        "colab_type": "text"
      },
      "source": [
        "#### Accuracy Score.\n",
        "- Let's see how the model performs on the data.\n",
        "- Prediction on the training and test data had accuracy score of 91%. This is a good model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kurY_F09VxEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3d8196f-1dfb-4a2f-93f5-f83861079e7f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# get the train score\n",
        "train_score = accuracy_score(train_pred, y_train)\n",
        "print('Train score is {}'.format(train_score))\n",
        "\n",
        "# get the test score\n",
        "test_score = accuracy_score(test_pred, y_test)\n",
        "print('Test score is {}'.format(test_score))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train score is 0.9155045118949959\n",
            "Test score is 0.9151731338089438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogHbrErbfzE",
        "colab_type": "text"
      },
      "source": [
        "### RBF Kernel\n",
        "- The rbf kernel is used for non-linear dataset. You use this when you linear model cannot accurately find the hyperplanes on you r non-linear data.\n",
        "- Implementating rbf kernel just needs you to assign the *rbf* value to the kernel parameter.\n",
        "- The implementation can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YOLXSGLdUxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model\n",
        "rbf_svm = svm.SVC(kernel='rbf')\n",
        "\n",
        "# fit the model on the training data\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on train data\n",
        "rbf_train_pred = rbf_svm.predict(X_train)\n",
        "\n",
        "# make prediction on test data\n",
        "rbf_test_pred = rbf_svm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VbFeR18cF_f",
        "colab_type": "text"
      },
      "source": [
        "#### Accuracy Score\n",
        "- When test against the train and test score, rbf performed better than the linear kernel with an accuracy score of approximately 92% on both train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryT7Kc-1emmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "571e4d96-d22c-408b-e30d-ffa31bd759db"
      },
      "source": [
        "# get the train score\n",
        "rbf_train_score = accuracy_score(rbf_train_pred, y_train)\n",
        "print('Train score is {}'.format(rbf_train_score))\n",
        "\n",
        "# get the test score\n",
        "rbf_test_score = accuracy_score(rbf_test_pred, y_test)\n",
        "print('Test score is {}'.format(rbf_test_score))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train score is 0.9214333656499366\n",
            "Test score is 0.9196102314250914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVaLnRgccsb6",
        "colab_type": "text"
      },
      "source": [
        "### Poly Kernel\n",
        "- The poly kernel is used for higly complex non-linear data.\n",
        "- Implemetation is similar to all the above examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF6cd5ujemhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model\n",
        "poly_svm = svm.SVC(kernel='poly')\n",
        "\n",
        "# fit the model on the training data\n",
        "poly_svm.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on train data\n",
        "poly_train_pred = poly_svm.predict(X_train)\n",
        "\n",
        "# make prediction on test data\n",
        "poly_test_pred = poly_svm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT6hdQsLc8JV",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy Score\n",
        "- We see that we get 92% on both train and test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHd-ivycemc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e0d2367f-4026-44c3-b60d-55327ec5e219"
      },
      "source": [
        "# get the train score\n",
        "poly_train_score = accuracy_score(poly_train_pred, y_train)\n",
        "print('Train score is {}'.format(poly_train_score))\n",
        "\n",
        "# get the test score\n",
        "poly_test_score = accuracy_score(poly_test_pred, y_test)\n",
        "print('Test score is {}'.format(poly_test_score))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train score is 0.9210604817659781\n",
            "Test score is 0.9190882199408387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvsjITaYdWsm",
        "colab_type": "text"
      },
      "source": [
        "### Sigmoid Kernel.\n",
        "- Implementing this is similar to everything we have been doing. The code is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdWXVyTvemVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model\n",
        "sig_svm = svm.SVC(kernel='sigmoid')\n",
        "\n",
        "# fit the model on the training data\n",
        "sig_svm.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on train data\n",
        "sig_train_pred = sig_svm.predict(X_train)\n",
        "\n",
        "# make prediction on test data\n",
        "sig_test_pred = sig_svm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ1GkgWcdipc",
        "colab_type": "text"
      },
      "source": [
        "####Accuracy Score.\n",
        "- This performed worst than all the other models.\n",
        "- 85% accuracy on both train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sntfV7phemSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc16b859-9799-4c39-daa6-b96de9c369db"
      },
      "source": [
        "# get the train score\n",
        "sig_train_score = accuracy_score(sig_train_pred, y_train)\n",
        "print('Train score is {}'.format(sig_train_score))\n",
        "\n",
        "# get the test score\n",
        "sig_test_score = accuracy_score(sig_test_pred, y_test)\n",
        "print('Test score is {}'.format(sig_test_score))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train score is 0.8583041240957566\n",
            "Test score is 0.8547938054637202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoaD6yexeB8m",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Tuning\n",
        "- We will now learn about the different parameters for SVM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLHOCNKSesBp",
        "colab_type": "text"
      },
      "source": [
        "#### Gamma\n",
        "- This is a hyperparameter used in non-linear hyperplanes, It is advisable to start with a low gamma value and move your way up and also keep it in mind that a high gamma value can cause your model to overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_vAqONpPCAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gammas = [0.1, 1, 10, 100]\n",
        "for gamma in gammas:\n",
        "   tuned_linear_svc = svm.SVC(kernel='rbf', gamma=gamma)\n",
        "   tuned_linear_svc.fit(X_train, y_train)\n",
        "   pred = tuned_linear_svc.predict(X_test)\n",
        "   print(accuracy_score(pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wxyqOGOe2u3",
        "colab_type": "text"
      },
      "source": [
        "#### C\n",
        "- Is the parameter that penalizes the error, it controls the trade off between our decision boundary and correctly classified data points.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH16N98vPB75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cs = [0.1, 1, 10, 100, 1000]\n",
        "for c in cs:\n",
        "  tuned_linear_c = svm.SVC(kernel='rbf', C=c)\n",
        "  tuned_linear_c.fit(X_train, y_train)\n",
        "  pred = tuned_linear_c.predict(X_test)\n",
        "  print(accuracy_score(pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmWLHulqe9NX",
        "colab_type": "text"
      },
      "source": [
        "#### Degree\n",
        "- This parameter is specifically targeted to the poly kernel, it is the degree of polynomial used to find the decision boundary to split the data. Using a degree =1 is the same as using a linear kernel and the higher the degree the linger the model will train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuCfnUyFPB4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degrees = [0, 1, 2, 3, 4, 5, 6]\n",
        "for degree in degrees:\n",
        "  tuned_linear_d = svm.SVC(kernel='poly', degree=degree)\n",
        "  tuned_linear_d.fit(X_train, y_train)\n",
        "  pred = tuned_linear_d.predict(X_test)\n",
        "  print(accuracy_score(pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcZclWoPeU_M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}